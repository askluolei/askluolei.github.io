---
title: redis 学习笔记
date: 2019-09-15 10:41:03
tags: [redis]
categories: 技术笔记
---

redis 之前只是会用，经常看一些博客和官网的使用说明，但是还没成体系的学习过
最近买了本 `Redis 开发与运维` ，买这本书对理由是我虽然会用，但是对譬如哨兵，集群方案，
内部 redis 之间是怎么通信对等一些细节不是很了解。想要详细了解下   

写这篇笔记，目的是，以后redis 相关等至少看自己等这篇笔记就可以了，不用经常回去翻书    
其实书早就看完了。感觉要补一篇学习笔记。顺便用耗子哥说的总结归纳方法试一下  
只归纳以下重点，具体细节就不罗列了

先套下学习模板  
1. 这个技术出现的背景，初衷和要达到什么样的目标或者是要解决什么样的问题
2. 这个技术的优势和劣势分别是什么，或者说，这个技术的 trade-off 是什么
3. 这个技术的适用场景
4. 技术的组成部分和关键点
5. 技术的底层原理和关键实现
6. 已有的实现和它之间的对比

## 这个技术出现的背景
`redis` 的作者实现原因是因为想要实现高性能的队列功能，用传统的 `mysql` 没办法达到性能要求
因此想要做一个专属的 `LLOOGG` 数据库。    
这样看起来，简单的来说，`redis` 的出现背景是针对 传统数据库存储的性能不足 

## 这个技术的优势和劣势分别是什么 
1. 速度快。 读写达到10w/s
2. 基于键值对对数据结构服务器。支持常用的数据结构
3. 丰富的功能。键过期，发布订阅，lua脚本，简单事务，流水线
4. 简单稳定。单线程模型
5. 支持的客户端语言多
6. 支持持久化
7. 主从复制
8. 高可用和分布式

## 这个技术的适用场景
1. 缓存。大部分使用场景都是这个
2. 消息队列系统。简单的消息队列，基于发布订阅或者阻塞队列。这个只针对简单的队列功能，无持久化，重复，等复杂功能
3. 排行榜和计数器应用。。。这是书上说的，感觉其实就是使用 `redis` 里面的数据结构实现的一些功能。

不适用的场景：1. 数据存储。`redis` 是基于内存的，不应该将全部数据或者冷数据放到 `redis` 

## 技术的组成部分和关键点 

**单线程模型**
首先，就是单线程模型，这个一定要知道。  
所谓单线程模型，不代表 redis 进程内部只有一个线程，而是，只用单线程处理客户请求的命令 
所以从客户端发请求到响应要经过以下过程：
1. 命令网络传输
2. 命令队列等待时间
3. 命令处理时间
4. 命令响应网络传输

通常 redis 保证命令处理时间很短，当然，在有大量 key 的 redis 使用 keys 命令也是会执行很长时间的

**数据结构**
支持5种数据结构。 string，hash，list，set，zset

string 内部编码是 
1. raw >39个字节的字符串
2. int 8个字节长整型
3. embstr <= 39 个字节的字符串 
hash 的内部编码：
1. hashtable  不满足下面的情况下使用
2. ziplist  hash类型元素个数小于 hash-max-ziplist-entries 默认 512 个，这个是一个紧凑的结构，节省内存
list 的内部编码是 
1. linkedlist 不满足下面的条件
2. ziplist 列表元素个数小于 list-max-ziplist-entries 默认 512 个，同时列表每个元素的值小于 list-max-ziplist-value 默认 64 字节
set 的内部编码是 
1. hashtable 不满足下面
2. intset 元素是整数，并且数量小于 set-man-intset-entries 
zset 的内部编码是 
1. skiplist 不满足下面条件
2. ziplist 元素个数小于 zet-max-ziplist-entries 默认 128 个 同时元素小于 zset-max-ziplist-value 默认 64 字节


**键过期**
`expire` 设置过期时间 和 `ttl` 查询存活时间，返回 -1 代表没设置过期时间，-2 键不存在  
键过期有两种方式，一种是惰性的，当访问到 key 到时候检查 key 过期了才移除，另一种是定时抽样检查移除过期的 key，如果比例大于 25%，继续进行抽样，直到运行超时 25ms 

**pipeline**
pipeline 简单点说，就是将一批命令，整体打包发送给 redis，这样节省了 客户端与redis 的网络通信时间

**持久化**
主要有两种持久化方式 rdb 和 aof 

1. rdb
rdb 相当于当前 redis 数据的快照，生成文件存放在硬盘    
分为自动触发和手动触发，手动使用 `bgsave` 自动就是配置 `save m n ` 标示 m 秒内有 n 次修改触发 
文件保存 dir 配置的目录下，文件名韦 dbfilename 配置 
rdb 没办法做到实时持久化，是一个紧凑的 二进制文件，redis 加载 rdb 文件比 aof 快

2. aof
就是以独立日志记录每次写命令，
开启需要 appendonly yes 配置开启 文件名为 appendfilename 配置 
里面关键的是文件同步策略。每次命令是写在缓冲区，什么时候刷盘，需要配置 appendfsync 有 always everysec no 默认是 everysec  
当 aof 文件很大的时候可以重写，直接使用当前 redis 的数据重写 aof 文件 
手动触发 使用命令 bgrewriteaof
自动触发 根据配置 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 

**事务**
将一组要执行的命令放在 multi  和 exec 命令中间  
可以使用 discard 命令停止事务 
如果命令过程中有语法错误，事务不执行
如果命令用错了，譬如 sadd 写成了 zadd ，错误前面的命令会执行。。

**支持主从复制**
主从是高可用的基础  
启动的时候使用配置 slaveof host port 配置
也可以在运行过程中执行命令 slaveof host port
查看主从信息，可以 info replication 命令  
断开主从，可以 slaveof no one 断开主从连接，不会删除已有数据，只是无法接收新的数据变化  
可以先断开主从，然后切换新的主节点，注意，切换过程中原有数据将删除，重新同步新的主节点数据，slave 默认只读  
每个 redis 节点根据 运行id 区分，每次启动都会动态分配一个 40 位的运行 id

**高可用-哨兵**
哨兵基于主从复制，在主节点出现故障的时候完成故障转移操作，提升一个从节点为主节点，并将其他从节点修改主节点地址  
判断主节点故障至少需要 n/2 + 1 个哨兵确认 
客户端获取主节点地址要通过哨兵获取，每监控一个主键点，其实就是一个 mastername，一套哨兵可以同时监控多个主节点

故障转移的步骤简单说
1. 判断主节点故障
2. 选择一个 sentinal 节点完成故障转移功能
3. 选择一个数据最全的从节点作为新的主节点
4. 切换

当然，中间有很多细节，就不写了。就算看了也估计就能记一段时间，这些概念还是能够理解的

**高可用-集群**
当数据量过大，单个节点存不下所有数据，需要多个 redis 节点分担的时候，使用 redis 集群方案  
数据分区规则：
根据虚拟槽分区，使用一个 hash 函数，将数据映射到一个 整数集合中，定义为 slot 槽，redis 到 slot 范围为 0 - 16383 
每个 redis 主节点负责一部分 slot，一个 redis 集群，必须每个 slot 都有节点负责，这个时候 redis 集群才能正常工作  

以集群模式启动 redis 需要配置 
cluster-enabled yes 
配置内部配置文件，这个通常是生成的配置
cluster-config-file node-port.conf  

然后完成节点握手 通过 gossip 流言协议，达到互相感知 
cluster meet host port 命令

然后分配 slot 
cluster addslots {0...5461} 

分配了slot 的节点可以认为是主节点，然后配置其他节点复制响应的主节点，根据 nodeid 复制 
cluster replicate nodeid

当然，手动配置比较复杂，使用 redis-trib.rb 搭建集群简单点 

当有新的节点加入，可以将部分 slot 转移个新节点
当有主节点退出，也可以将他负责的 slot 转移给其他节点

## 已有的实现和它之间的对比 
memcached 多线程模型，只支持 key value  
好吧，其实我没用过，也没了解过这个东西。。


## 其他 
除了上面的5个数据结构，还有一些扩展 

**位图**
bitmap
事件上是字符串，内部存 0 1 
命令 setbit key offset value    getbit key offset 
还有一些其他的命令，用到的时候可以详细看  

**hyperloglog**
这实际上是一个基数算法，可以使用更少的内存空间完成集合运算，当然存在一定误差

**pub/sub**
基于频道的发布订阅，之前高可用内部通信很多都是基于这个  
可以看着简单的队列  
命令：
publish chennel message
subscribe channel 
unsubscribe channel

**geo**
地理位置信息
geoadd key longtitude latitude member 。。。

完成地理位置信息的录入后，可以做些计算。。没用过  

**stream**
redis5 新增的一个消息队列 
与 kafka 类型，之前的发布订阅，订阅者可以获取全量数据，并且无法获取之前的数据 
stream 目前会存一份原数据，消费者也分为消费者组，每个组消费全量数据，组内每个消费者竞争获取
